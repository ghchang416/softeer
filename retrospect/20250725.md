## 리뷰

---

오늘 할 일

- 미션은 무조건 다 끝내자

### **Hadoo**p Streaming 개념 및 동작 방식 이해

- Hadoop은 기본적으로 Java 기반 MapReduce를 지원하지만,
- Hadoop Streaming 기능을 사용하면 Python, Bash 등 타 언어로도 MapReduce 작업 수행 가능
- Streaming은 stdin/stdout 기반의 Unix 파이프라인 방식으로 작동
    - 예) `mapper.py`의 `print()` 출력 → stdout → Hadoop이 받아서 다음 단계로 전달
- 사용 시 유의사항:
    - `mapper.py`, `reducer.py` 스크립트의 첫 줄에 해당 언어 인터프리터 명시 (`#!/usr/bin/env python3`) 필요
    - 그렇지 않으면 Hadoop이 단순 텍스트로 인식함

### **Hadoop 클러스터에서의 사용자 권한 설정 전략**

- 클러스터 운영 시 `root` 사용자로 직접 하둡을 돌리는 것은 지양
- 이유:
    - 보안 문제: 루트 권한 노출 시 시스템 전체에 영향 가능
    - 사용자 간 권한 분리 불가
- 해결 방안:
    - 시스템 초기 설정(SSH 키 설정, 패키지 설치 등)은 root에서 수행
    - Hadoop 서비스는 일반 사용자에게 위임하여 실행
    - 일반 사용자에게는 `$HADOOP_HOME` 이하 디렉토리만 접근 허용

### **MapReduce의 내부 처리 흐름**

- Mapper 단계
    - 입력 데이터를 (key, value)로 처리하여 출력
- Shuffle & Sort 단계 (자동)
    - Hadoop이 모든 Mapper 출력 데이터를 key 기준으로 정렬 및 그룹핑
- Reducer 단계
    - 정렬된 key 그룹별로 데이터를 받아 최종 처리

### **대규모 데이터 처리 시 설정 고려사항**

- 처음에는 단순히 DataNode 수를 늘려서 처리 성능 향상을 기대했으나, 에러 발생
- 원인:
    - 클러스터 리소스 설정 (메모리, replication 등)이 충분히 고려되지 않음
    - 단순히 노드를 늘리는 것만으로는 해결되지 않음 → ResourceManager, block size, 메모리 설정 등을 함께 조율해야 안정적

### 강의 내용

- 미션 수행 시, 데이터 수집 주기를 얼마로 잡을 것인지 설정하는 것 또한 중요하다
- 초기 아이디어 단계에서부터 꼭 대규모 데이터가 필요한 것은 아님
- 초기에는 소규모 데이터로 시작해도 되고, 사업 확장에 따라 커질 수 있음
- "어떤 문제를 풀 것인가?" → 그것과 연결된 데이터를 어떻게 수집할 것인가?
- 분석 기법이나 AI 알고리즘은 이후 전문가가 다룰 수 있으므로, 지금은 문제 정의와 데이터 확보에 집중

**벤치마킹의 함정**

- 경쟁사의 기능/운영을 따라 하는 것은 가능하지만,
- 그 결정의 배경(why)은 외부에서 절대 알 수 없다
- 따라서 모방만으로는 성공하기 어렵고, 의사결정의 근거를 파악하거나 직접 논리를 구성할 수 있어야 함

## 회고

---

### Keep

- 컨테이너 내부를 루트 사용자로 접근하지 않고, 새로운 일반 사용자를 생성하여 과제를 수행함으로써 운영 환경에서의 권한 관리 원칙을 준수하였다.

### Problem

- 설정된 볼륨을 매핑했을 때, 파일 접근 권한 문제가 반복되어 해결을 시도하는 과정에서 매핑을 제거했음. 이때 실수로 전체 Docker 캐시를 삭제해버렸고, 그로 인해 이전에 빌드해두었던 이미지까지 모두 사라짐. 결과적으로 이미지를 처음부터 다시 빌드해야 했고, 예상치 못한 시간 낭비가 발생함. 다음부터는 삭제 시 옵션 범위를 명확히 설정하여 불필요한 리소스 손실을 방지하겠다.

### Try

-
