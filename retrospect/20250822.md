## 리뷰

---

## 강의 정리: How `LocalShuffleReaderExec` Works

### 핵심 개념

- 데이터 locality를 최대한 활용하는 것이 효율적임.
- AQE는 각 shuffle partition이 어느 노드에 가장 많이 있는지 알려주고, TaskSetManager(TSM)는 이 정보를 활용해 태스크를 스케줄링함.
- 실행 순서는 다음과 같음:
    
    PROCESS_LOCAL → NODE_LOCAL → NO_PREF → RACK_LOCAL → ANY
    

---

### Locality Level별 동작

1. PROCESS_LOCAL
    - 대상: 데이터를 가진 특정 executor의 빈 슬롯
    - 특징: 최상의 locality (데이터가 메모리에 있음).
    - 전략: 즉시 실행하지 않고 잠시 기다려 executor가 비면 실행.
2. NODE_LOCAL
    - 대상: 데이터가 있는 노드 내 모든 executor의 빈 슬롯
    - 특징: 디스크/loopback I/O로 접근 가능 → 비용 낮음.
3. NO_PREF
    - 대상: 없음 (즉시 실행)
    - 특징: 데이터 위치와 무관 → 실행 지연 없이 바로 시작.
    - 예시: broadcast join, object storage 입력.
4. RACK_LOCAL
    - 대상: 동일 랙(rack)의 다른 노드 executor 빈 슬롯
    - 특징: 네트워크 hop은 짧아 비용 중간.
    - 비고: `spark.locality.rack` 옵션 활성화 필요.
5. ANY
    - 대상: 없음 (즉시 실행)
    - 특징: 네트워크를 반드시 타야 하는 경우 → 지연할 가치 없음.

---

### Delay Scheduling

- 목적: 데이터 locality가 좋은 executor에서 실행해 네트워크 I/O를 최소화하고 성능을 높임.
- 하지만 무작정 기다리면 job 전체 지연 → `spark.locality.wait` 타임아웃 설정 후, 점진적으로 locality 수준을 낮추며 실행.
- 즉, relax = 더 좋은 locality를 우선 시도하다가 점차 차선책으로 떨어지는 과정.

---

### Catalyst Optimizer와 차이

- Catalyst Optimizer는 rule-based라서 실행 전 계획(logical/physical plan)까지만 가능.
- Locality는 런타임 시점에 실제 executor 배치 상태를 알아야 함 → Catalyst만으로는 불가능.
- 따라서 이 기능은 AQE가 도입된 후, query stage 단위로 런타임 최적화가 가능해지면서 지원됨.

---

## 팀 활동 정리

1. **스케줄링 및 관리**
    - 월요일까지 할 일 리스트 작성, 타임박싱 후 태스크 분배.
    - 간트 차트로 시각화하여 매일 업데이트 → 진행 상황과 계획 대비 현황 파악.
2. **평가 지표 다각화**
    - 단일 지표(가격)만 사용하지 않음.
    - **가격 + 전문성** 등 복수 지표를 활용해 평가 지표 산출.
    - 팀 내 논의 후, 종합 score 설계.
3. **정비소 리뷰 분석**
    - 리뷰 데이터를 기반으로 정비소 특징(키워드) 추출.
    - 정비소 태그 ↔ 견적서 태그 매핑 → 해당 정비소의 전문성 드러냄.
4. **UI 설계**
    - 사용자에게 어떤 지표(가격/전문성/score)를 보여줄지 UI를 통해 결정.
    - 사용자 친화적 지표 제공을 목표로 함.

## 회고

---

### Keep

간트 차트로 작업 일정을 타임 박싱하고 팀원별로 태스크를 분배하자, 내가 맡은 업무가 무엇인지 시각적으로 정리되어 바로 확인할 수 있었다.

### Problem

### Try
