## 리뷰

---

오늘 할 일

- 팀 프로젝트 인사이트 도출
- 강의 정리
- W4M1 미션 수행

### 강의

**소프트웨어 버전 중요성**

- Spark, Hadoop 등 버전에 따라 명령어 및 호환성이 다르므로 주의.

**데이터 볼륨 연결**

- Docker 볼륨을 통해 입력/출력 데이터를 컨테이너와 연결함.
- 장점: 컨테이너를 껐다 켜도 데이터가 유실되지 않음.
- 단점: 노드 수가 많을수록 볼륨 복제 비용 증가, 노드마다 로컬 파일 필요. → 데이터를 목적에 맞게 분리

**Spark 등장 배경**

1. 빅데이터의 폭발 (SNS, 로그 등 실시간 데이터 증가)
2. 클라우드 기반 확산 → 빠르고 반복적인 처리 요구
3. 하둡의 한계 (RAM 사용 안 함, 반복 작업 느림)
4. 스트리밍 처리 요구 증가

**Spark의 기술적 특징**

- 인메모리 연산 (메모리 기반 캐시) → 반복 연산에 유리
- 하둡은 HDFS가 fault tolerance를 담당하지만 Spark는 RDD에서 lineage 기반으로 복구
- Application 간 메모리 공유하지 않음

**클러스터 매니저의 종류**

| 모드 | 설명 |
| --- | --- |
| local | 단일 머신, 단일 JVM (제일 빠름) |
| standalone | Spark 자체 제공 매니저, 가볍고 빠름 |
| cluster | 외부 리소스 매니저와 함께 사용 (YARN, Mesos 등) |

### Spark Standalone Cluster 실행 구조

1. 사용자가 `spark-submit` 명령을 실행.
2. 클라이언트는 마스터 노드에 애플리케이션 제출.
    - 클라이언트는 제출만 하고 이후 작업에 직접 개입하지 않음 (cluster mode 기준).
3. 마스터는 드라이버를 실행할 노드를 선정하여 드라이버 실행을 요청.
    - Application Master을 실행하는 것 (= Spark Application)
    - 이때 드라이버 JVM이 실행되며, 내부에는 `SparkContext`, `DAG Scheduler`, `Task Scheduler` 등이 포함.
4. Spark Application(이하 드라이버)이 리소스 매니저에게 자원을 할당해달라고 요청하고, 리소스 매니저는 각 노드 매니저를 통해 Executor를 실행.
5. 드라이버는 클러스터 내의 각 워커 노드에 Executor 실행 요청을 전송.
6. 각 워커 노드는 Executor JVM을 스폰하여 실행.
    - Executor는 각자 독립된 JVM으로 동작하며, 메모리 공간(JVM heap)을 가지고 작업 수행.
7. Executor는 Driver와 통신하며 작업을 받아 실행.
    - 작업 결과도 Driver에 전달.

**Deploy Mode 비교**

| Mode | Driver 위치 | 특징 |
| --- | --- | --- |
| client | 사용자 머신 | 개발 시 사용, submit 노드 죽으면 실패 |
| cluster | 클러스터 내 노드 | 운영 환경용, submit 노드와 분리 |
| local | 모두 동일 머신 | 테스트 전용 |

---

**W4M1 실습**

- Spark에서 `file:/` 경로 사용 시 모든 워커 노드도 해당 경로를 직접 읽을 수 있어야 함.
    - 예: `/opt/spark/input/text.txt`
    - 해결: 모든 컨테이너(`spark-master`, `spark-worker-*`)에 같은 볼륨 마운트 필요

---

### 느낀 점

- 단순히 실행만 하는 것이 아니라, 왜 `deploy mode`라는 개념이 나왔는지를 고민해 보기
    - 기존에는 사용자의 클라이언트 머신이 실행을 끝까지 책임져야 해서 중간에 끊기면 애플리케이션이 실패하는 문제가 있었음. 이를 해결하기 위해 `cluster mode`가 등장했고, 실제 운영 환경에서는 이를 주로 사용.
- 실행 시점에 Driver와 Executor의 위치가 달라짐에 따라 네트워크 통신 구조와 배포 전략이 달라진다는 점이 인상 깊었다.

## 회고

---

### Keep

- 강사님께서 강조하신 것처럼, 기술을 학습할 때 단순한 사용법만 익히는 것이 아니라 "왜 이런 구조가 필요했는가?"라는 배경과 맥락을 이해하는 것이 중요하다는 점을 실감했다. 실제로 이러한 배경 지식을 함께 학습하니 기술의 구조와 목적이 더욱 명확하게 다가왔고, 앞으로도 어떤 기술이든 단순히 사용하는 것에 그치지 않고 “왜?”라는 질문을 던지며 탐구하는 학습 방식을 유지하고자 한다.

### Problem

- 

### Try

- 하둡과 스파크의 통신 아키텍처 구조는 글이나 말만으로는 직관적으로 이해하기 어려운 부분이 많았다. 실행 흐름이나 구성 요소 간의 관계가 복잡하게 얽혀 있어, 머릿속으로만 그리다 보면 놓치는 부분이 생기곤 했다.
- 앞으로는 강의나 실습 중에 노트와 펜을 준비하여 직접 통신 구조를 하나하나 그려보며 흐름을 정리할 계획이다. 눈으로 보고 손으로 그리며 반복적으로 구조를 익히는 방식이 아키텍처 이해에 훨씬 효과적일 것이라 생각한다.
