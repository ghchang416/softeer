## 리뷰

---

### 오늘 할 일

- 강의
- 아키텍처 설계 수정
- 리뷰 데이터를 통해 어떻게 인사이트 뽑을지

## Catalyst Optimizer & AQE 정리

### 1. Catalyst Optimizer 개요

- Spark SQL의 핵심은 **규칙 기반(rule-based) 최적화**이다.
- 사용자가 작성한 **SQL 쿼리 + DataFrame API 코드** → **Logical Plan**으로 변환.
- Logical Plan은 DAG와 유사한 개념으로, 이를 기반으로 **Physical Plan**을 생성한다.
- Physical Plan 생성 시, Spark는 다양한 후보 실행 계획을 만들고 **Cost Model**로 리소스 사용량을 추정해 최적의 실행 전략을 선택한다.
    
    (예: Broadcast Join vs Sort-Merge Join)
    

**특징**

- 여러 Stage를 하나의 함수(Java Bytecode)로 합쳐 Shuffle 등의 복잡성을 줄인다.
- 하지만 데이터의 실제 분포(skew)나 하드웨어 상황(메모리 등)에 따라 계획이 달라질 수 있어, 초기 Cost Model은 **추정치**에 불과하다.

---

### 2. Adaptive Query Execution (AQE)

- AQE는 **실행 중(runtime)** 에도 쿼리 계획을 **동적으로 조정**할 수 있는 기능.
- 핵심 아이디어: **Query Stage** 단위로 쪼개 실행 → 통계(statistics) 수집 → 다음 Stage 실행 전 플랜 재최적화.

**장점**

- 데이터 스큐(skew) 완화
- 예측 불가능한 데이터 크기에서도 성능 개선
- 최적화된 파이프라인으로 빠른 처리 가능

**주요 기법**

1. **Dynamic Partition Pruning**
    - 작은 테이블을 필터링 후 해시 테이블로 만들어 큰 테이블에서 필요한 데이터만 효율적으로 Join.
    - 조건은 반드시 Join Key 기반이어야 하며, 필요 시 작은 테이블에 컬럼을 추가해 확장 가능.
2. **CoalesceShufflePartitions**
    - 실행 중 파티션 크기를 보고 동적으로 병합(coalesce) 또는 분리(split).
    - → 너무 큰 파티션 → 메모리 부족, spill 발생
    - → 너무 작은 파티션 → Task 오버헤드 증가
    - → 적절한 병렬성을 유지하며 성능 개선
3. **Join 최적화**
    - **Shuffle Hash Join**: 작은 테이블을 메모리에 올려 해시 기반 Join (빠르지만 spill 가능)
    - **Sort-Merge Join**: 정렬 후 병합 방식 (안정적이나 정렬 비용 큼)
    - AQE는 실행 통계에 따라 Join 방식을 동적으로 교체 가능.
4. **OptimizeLocalShuffleReader**
    - 네트워크 비용을 줄이기 위해, 가능한 **가까운 위치(local)의 Shuffle 데이터**를 읽도록 최적화.

---

### 3. AQE를 쓰지 않아도 되는 경우

- 데이터가 작고 셔플이 거의 없는 단순 Job
- 데이터 특성을 완전히 파악하고 있어, 실행 계획에 대한 확신이 있을 때

---

## 아키텍처 설계 (수정)

### 1. 서비스 요구사항

- **입력:** 견적서 (차량 정보, 부품/공임 리스트, 총액)
- **출력 API:**
    1. 견적서 자체 평가 (과잉 정비 여부)
    2. 견적서 비교 평가
    3. 정비소 추천 (정보/리뷰 데이터 기반)

### 2. 아키텍처 방향

- **빠른 프로토타입 제작** 우선
    - Kafka, Streaming 제거
    - OCR, LLM은 후순위 → 추후 기능 확장 시 도입
    - 우선은 REST API 구조로 빠르게 결과 반환
- **신뢰성 강화**
    - OCR 대신, **장애 대응/예외 처리 설계**가 더 우선순위 높음
    - 확장성 고려: 이후 OCR/LLM 모듈을 플러그인처럼 붙일 수 있도록 설계

---

## API 명세 예시

### 1. 견적서 평가

**POST /estimate**

- 입력: 차량 정보 + 부품/공임 리스트 + 총액
- 출력: 과잉 정비 여부, 총액 대비 합리성 점수

### 2. 부품 가격 평가

**POST /compare**

- 입력: 견적서 ids
- 출력: 견적서 점수, 추천 견적서와 그 이유

### 3. 정비소 추천

**GET /repairshop/recommend**

- 입력: 위치, 차량 모델
- 출력: 평점/리뷰 기반 추천 정비소 리스트

---

## 리뷰 데이터 활용 방안

### 1. 현황

- **카닥:** 수리 퀄리티, 친절도, 견적 정확도 → 정형화된 카테고리 제공
- **마이클:** 카테고리 없음 → 텍스트 리뷰만 존재

### 2. 문제

- 두 플랫폼 데이터를 직접 정합하기 어려움 (형식 불일치)
- 단순 워드 카운트로는 신뢰성 부족

### 3. 해결책

- 리뷰 텍스트를 **감정분석 모델(Sentiment Analysis)** 에 통과
- 각 리뷰를 `0~1 confidence score` 로 정량화
- 이를 기반으로:
    - 정비소의 "견적 정확도" 점수 추정
    - 추천 알고리즘에 반영 (e.g. 긍정 리뷰 비율, 최근성 가중치)

⚠️ 단, 감정분석 기반 결과가 실제 고객 니즈와 항상 일치하지는 않음 → 추가 보완 필요

## 회고

---

### Keep

요청/응답 스펙을 구조화하니, 서비스에 꼭 필요한 기능과 나중에 분리·확장해야 할 모듈이 명확해졌다. 앉아서 고민만 하기 보단 문서를 작성하며 직접 해보는 것이 중요한 것 같다.

### Problem

### Try
